{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5851448c-efb6-4d86-8896-1d7c1823ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b322e-7bcf-4256-aff6-c9ce4a65c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_err(est, true):\n",
    "    \"\"\"Calculate the normalized standard dev. for each Noll index.\"\"\"\n",
    "    # Norms from simulation scripts\n",
    "    #norms = np.arange(1, 20) ** -1.5\n",
    "    j = np.arange(4, 23)\n",
    "    nu = np.array([0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 2, 2, 1, 1, 0, 0, 2])\n",
    "    norms = 10.0 ** (-6 - nu) / (j - 3)**(0.5) / 2\n",
    "    norms *= 1e6\n",
    "\n",
    "    # Calculate normalized residuals\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        resid = (est - true) / true # norms\n",
    "\n",
    "    # Robust standard dev\n",
    "    iqr = np.percentile(resid, 75, axis=0) - np.percentile(resid, 25, axis=0)\n",
    "    std = iqr / 1.35\n",
    "    \n",
    "    return std\n",
    "\n",
    "def symmetrize(errs):\n",
    "    pairs = np.array([[5, 6], [7, 8], [9, 10], [12, 13], [14, 15], [16, 17], [18, 19], [20, 21]])\n",
    "    for pair in pairs:\n",
    "        errs[pair - 4] = np.mean(errs[pair - 4])\n",
    "    return errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943130bd-87d6-4f31-8548-4e3f14ae3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(7, 5.55), dpi=150)\n",
    "\n",
    "# Sparse Zernikes\n",
    "with open(\"sims/sparse_zk_estimates_full.pkl\", \"rb\") as file:\n",
    "    full = pickle.load(file)\n",
    "with open(\"sims/sparse_zk_estimates_shape.pkl\", \"rb\") as file:\n",
    "    shape = pickle.load(file)\n",
    "\n",
    "full_errs = calc_err(full[\"est\"], full[\"true\"])\n",
    "shape_errs = calc_err(shape[\"est\"], shape[\"true\"])\n",
    "\n",
    "z4_full = full_errs[0]\n",
    "\n",
    "ax1.errorbar(\n",
    "    np.arange(4, 23) + 0.1,\n",
    "    0 * np.arange(4, 23),\n",
    "    yerr=shape_errs,\n",
    "    c=\"C0\", ls=\"\",\n",
    ")\n",
    "\n",
    "ax1.errorbar(\n",
    "    np.arange(4, 23) - 0.1,\n",
    "    0 * np.arange(4, 23),\n",
    "    yerr=full_errs,\n",
    "    c=\"C1\", ls=\"\",\n",
    ")\n",
    "\n",
    "ax1.errorbar([], [], yerr=[], c=\"C1\", ls=\"\", label=\"Shape + intensity\")\n",
    "ax1.errorbar([], [], yerr=[], c=\"C0\", ls=\"\", label=\"Shape only\")\n",
    "ax1.legend(frameon=False, ncols=2, handlelength=1)\n",
    "\n",
    "# Dense Zernikes\n",
    "with open(\"sims/dense_zk_estimates_full.pkl\", \"rb\") as file:\n",
    "    full_dan = pickle.load(file)\n",
    "with open(\"sims/dense_zk_estimates_shape.pkl\", \"rb\") as file:\n",
    "    shape_dan = pickle.load(file)\n",
    "with open(\"sims/dense_zk_estimates_full_tie.pkl\", \"rb\") as file:\n",
    "    full_tie = pickle.load(file)\n",
    "with open(\"sims/dense_zk_estimates_shape_tie.pkl\", \"rb\") as file:\n",
    "    shape_tie = pickle.load(file)\n",
    "\n",
    "# TIE is good at most of this, but sucks at coma due to miscentering\n",
    "# Danish does well on coma, but screws other stuff up to it being unstable\n",
    "# in shape prediction mode when using higher-order modes\n",
    "# Let's just grab the min for each Noll index. I think this captures the\n",
    "# general behavior without getting lost in the weeds of trying to design\n",
    "# the perfect shape-based wavefront estimator that is stable for all modes\n",
    "full_errs = np.min([\n",
    "    calc_err(full_dan[\"est\"], full_dan[\"true\"]),\n",
    "    calc_err(full_tie[\"est\"], full_tie[\"true\"]),\n",
    "], axis=0)\n",
    "full_errs[0] = z4_full\n",
    "shape_errs = np.min([\n",
    "    calc_err(shape_dan[\"est\"], shape_dan[\"true\"]),\n",
    "    calc_err(shape_tie[\"est\"], shape_tie[\"true\"]),\n",
    "], axis=0)\n",
    "\n",
    "ax2.errorbar(\n",
    "    np.arange(4, 23) + 0.1,\n",
    "    0 * np.arange(4, 23),\n",
    "    yerr=symmetrize(shape_errs),\n",
    "    c=\"C0\", ls=\"\",\n",
    ")\n",
    "\n",
    "ax2.errorbar(\n",
    "    np.arange(4, 23) - 0.1,\n",
    "    0 * np.arange(4, 23),\n",
    "    yerr=symmetrize(full_errs),\n",
    "    c=\"C1\", ls=\"\",\n",
    ")\n",
    "\n",
    "# Axes\n",
    "for ax in (ax1, ax2):\n",
    "    ax.set(\n",
    "        xlabel=\"Noll index\",\n",
    "        ylabel=\"Relative error\",\n",
    "        xticks=np.arange(4, 23),\n",
    "    )\n",
    "    \n",
    "ax1.set_ylim(*ax2.get_ylim())\n",
    "\n",
    "fig.subplots_adjust(hspace=0.35)\n",
    "fig.savefig(\"figures/zk_estimates.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d684e19-3051-4495-ad09-fb468b39b469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
